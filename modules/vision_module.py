"""
M√≥dulo de visi√≥n que usa CNN local para detectar emociones
Basado en el c√≥digo de Google Colab
"""
# Importa os para operaciones del sistema
import os  # Para operaciones del sistema
# Importa numpy para operaciones num√©ricas
import numpy as np  # Para operaciones num√©ricas
# Importa PIL para manejo de im√°genes
from PIL import Image  # Para manejo de im√°genes
# Importa funciones de Keras para cargar modelos y procesar im√°genes
from tensorflow.keras.models import load_model  # Para cargar modelos Keras
from tensorflow.keras.preprocessing.image import img_to_array  # Para convertir im√°genes a arrays
# Importa logger para mensajes de depuraci√≥n
from loguru import logger  # Logger para depuraci√≥n
# Importa tipos para anotaciones
from typing import Dict  # Tipos para anotaciones

# Importa configuraci√≥n global de usuarios y emociones
from config import USERS, EMOTIONS  # Configuraci√≥n global

class VisionModule:
    """
    M√≥dulo de visi√≥n que usa CNN local para detectar emociones
    """
    
    def __init__(self):
        self.logger = logger  # Logger para mensajes
        self.model = None  # Modelo CNN (se carga despu√©s)
        self.classes = []  # Lista de clases del modelo
        self.img_height, self.img_width = 96, 96  # Tama√±o esperado de la imagen
        
        # Cargar modelo al inicializar
        self._load_models()
        
    def _load_models(self):
        """
        Carga el modelo CNN. Si no existe, entrena y guarda autom√°ticamente.
        """
        try:
            model_path = "models/emotion_model.h5"  # Ruta al modelo
            classes_path = "models/classes.json"  # Ruta a las clases

            # Verifica que existan los archivos del modelo y clases
            if os.path.exists(model_path) and os.path.exists(classes_path):
                self.model = load_model(model_path)  # Carga el modelo
                # Cargar clases del modelo desde JSON
                import json
                with open(classes_path, 'r', encoding='utf-8') as f:
                    self.classes = json.load(f)  # Carga las clases
                self.logger.info("‚úÖ Modelo CNN cargado correctamente")
                self.logger.info(f"üìã Clases disponibles: {len(self.classes)}")
            else:
                self.logger.warning(f"‚ö†Ô∏è Modelo no encontrado en {model_path}. Entrenando modelo nuevo...")
                # Entrenar y guardar modelo autom√°ticamente
                success = self.train_from_emociones()
                if success:
                    self.model = load_model(model_path)
                    import json
                    with open(classes_path, 'r', encoding='utf-8') as f:
                        self.classes = json.load(f)
                    self.logger.info("‚úÖ Modelo CNN entrenado y cargado correctamente")
                else:
                    self.logger.error("‚ùå No se pudo entrenar el modelo CNN")
        except Exception as e:
            self.logger.error(f"‚ùå Error al cargar o entrenar modelos: {e}")
    
    def _preprocess_image(self, image: Image.Image) -> np.ndarray:
        """
        Preprocesa la imagen exactamente como en el c√≥digo de Colab (resize directo a 96x96, sin recorte cuadrado).
        """
        try:
            # Convertir a RGB si es necesario
            if image.mode != 'RGB':
                image = image.convert('RGB')  # Convierte a RGB
            # Redimensionar exactamente a 96x96 (sin recorte)
            image = image.resize((96, 96))  # Redimensiona
            # Convertir a array y normalizar
            image_array = img_to_array(image)  # Convierte a array
            image_array = image_array / 255.0  # Normaliza
            # Agregar dimensi√≥n de batch
            image_array = np.expand_dims(image_array, axis=0)  # A√±ade dimensi√≥n batch
            return image_array
        except Exception as e:
            self.logger.error(f"Error al preprocesar imagen: {e}")  # Log de error
            raise  # Relanza excepci√≥n
    
    def detect_emotion(self, image_path: str) -> Dict:
        """
        Detecta la emoci√≥n en la imagen usando el modelo CNN
        Proceso simplificado como en el c√≥digo de Colab
        """
        try:
            # Cargar imagen desde el path
            image = Image.open(image_path)  # Abre la imagen
            
            # Preprocesar imagen completa (sin detectar rostros, como en Colab)
            processed_image = self._preprocess_image(image)  # Preprocesa
            
            if self.model is not None and len(self.classes) > 0:
                # Hacer predicci√≥n (como en Colab)
                prediction = self.model.predict(processed_image, verbose=0)  # Predice
                class_index = np.argmax(prediction[0])  # √çndice de clase
                
                if class_index < len(self.classes):
                    predicted_class = self.classes[class_index]  # Clase predicha
                    confidence = float(prediction[0][class_index])  # Confianza
                    
                    self.logger.info(f"Clase detectada: {predicted_class} (confianza: {confidence:.3f})")  # Log
                    
                    return {
                        "emotion": predicted_class,  # Emoci√≥n detectada
                        "confidence": confidence,  # Confianza
                        "success": True  # √âxito
                    }
                else:
                    return {"success": False, "error": "Error en predicci√≥n del modelo"}  # Error de predicci√≥n
            else:
                # Fallback si no hay modelo cargado
                import random
                emotion = random.choice(self.classes) if self.classes else "neutral"  # Emoci√≥n aleatoria
                confidence = random.uniform(0.6, 0.9)  # Confianza aleatoria
                
                return {
                    "emotion": emotion,  # Emoci√≥n fallback
                    "confidence": confidence,  # Confianza fallback
                    "success": True  # √âxito
                }
                
        except Exception as e:
            self.logger.error(f"Error al detectar emoci√≥n: {e}")  # Log de error
            return {"success": False, "error": str(e)}  # Devuelve error
    

    def process_image(self, image_path: str) -> Dict:
        """
        Procesa una imagen: identifica usuario y emoci√≥n
        """
        try:
            # Hacer una sola predicci√≥n (m√°s eficiente)
            result = self.detect_emotion(image_path)  # Predicci√≥n
            if result["success"]:
                predicted_class = result["emotion"]  # Clase predicha
                confidence = result["confidence"]  # Confianza
                # Extraer emoci√≥n real (puede venir como 'abrahan_feliz', 'jesus_triste', etc.)
                emotion_found = None  # Inicializa emoci√≥n
                pred_lower = predicted_class.lower()  # Min√∫sculas
                # 1. Coincidencia exacta
                if pred_lower in EMOTIONS:
                    emotion_found = pred_lower
                # 2. Coincidencia por prefijo/sufijo
                if not emotion_found:
                    for emo in EMOTIONS:
                        if pred_lower.endswith(emo) or pred_lower.startswith(emo):
                            emotion_found = emo
                            break
                # 3. Coincidencia aproximada (m√°s parecida)
                if not emotion_found:
                    close = difflib.get_close_matches(pred_lower, EMOTIONS, n=1, cutoff=0.6)
                    if close:
                        emotion_found = close[0]
                if not emotion_found:
                    emotion_found = "emoci√≥n desconocida"  # Fallback
                # Determinar usuario basado en la clase predicha
                if "abrahan" in pred_lower:
                    user_id = "abrahan"
                    user_name = "Abrahan"
                elif "jesus" in pred_lower:
                    user_id = "jesus"
                    user_name = "Jesus"
                else:
                    user_id = "abrahan"
                    user_name = "Desconocido"
                return {
                    "user_id": user_id,  # ID usuario
                    "user_name": user_name,  # Nombre usuario
                    "user_confidence": confidence,  # Confianza usuario
                    "emotion": emotion_found,  # Emoci√≥n
                    "emotion_confidence": confidence,  # Confianza emoci√≥n
                    "success": True  # √âxito
                }
            else:
                return result  # Devuelve error
        except Exception as e:
            self.logger.error(f"Error al procesar imagen: {e}")  # Log de error
            return {"success": False, "error": str(e)}  # Devuelve error
    
    def test_connection(self) -> bool:
        """
        Prueba si el modelo est√° cargado correctamente
        """
        try:
            if self.model is not None:
                self.logger.info("‚úÖ Modelo CNN disponible")  # Log de √©xito
                return True  # Modelo disponible
            else:
                self.logger.warning("‚ö†Ô∏è Modelo CNN no cargado")  # Log de advertencia
                return False  # Modelo no disponible
        except Exception as e:
            self.logger.error(f"Error al verificar modelo: {e}")  # Log de error
            return False  # Devuelve False

    def train_from_emociones(self, dataset_dir='emociones', epochs=20, batch_size=32):
        """Entrena el modelo CNN usando las im√°genes de la carpeta 'emociones/' y guarda el modelo y las clases. Devuelve True si tiene √©xito, False si falla."""
        # Importa librer√≠as necesarias para entrenamiento
        import numpy as np
        from PIL import Image
        from tensorflow.keras.utils import to_categorical
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
        from tensorflow.keras.optimizers import Adam
        from sklearn.model_selection import train_test_split
        import json, os

        IMG_SIZE = self.img_height  # Tama√±o de imagen
        X, y = [], []  # Listas para datos e √≠ndices
        class_names = set()  # Conjunto de nombres de clases
        for root, dirs, files in os.walk(dataset_dir):
            for file in files:
                if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp', '.gif')):
                    img_path = os.path.join(root, file)
                    label = os.path.basename(root).split('_')[-1].lower()
                    class_names.add(label)
                    try:
                        img = Image.open(img_path).convert('RGB')
                        img = img.resize((IMG_SIZE, IMG_SIZE))
                        img = np.array(img) / 255.0
                        X.append(img)
                        y.append(label)
                    except Exception as e:
                        print(f"Error cargando {img_path}: {e}")
        if not X or not y or not class_names:
            self.logger.error("‚ùå No se encontraron datos para entrenamiento.")
            return False
        X = np.array(X)
        class_names = sorted(list(class_names))
        y_idx = [class_names.index(lbl) for lbl in y]
        y_cat = to_categorical(y_idx, num_classes=len(class_names))
        X_train, X_val, y_train, y_val = train_test_split(X, y_cat, test_size=0.2, random_state=42)
        # Definir modelo simple CNN
        model = Sequential([
            Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),
            MaxPooling2D((2, 2)),
            Conv2D(64, (3, 3), activation='relu'),
            MaxPooling2D((2, 2)),
            Flatten(),
            Dense(128, activation='relu'),
            Dropout(0.5),
            Dense(len(class_names), activation='softmax')
        ])
        model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])
        model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val), verbose=2)
        # Guardar modelo y clases
        os.makedirs('models', exist_ok=True)
        model.save('models/emotion_model.h5')
        with open('models/classes.json', 'w', encoding='utf-8') as f:
            json.dump(class_names, f, ensure_ascii=False, indent=2)
        self.logger.info("‚úÖ Modelo y clases guardados en 'models/'")
        return True 